---
title: 贝叶斯分类器实现
date: 2017-10-14 19:03:31
categories:
- Machine Learning
tags: 
- 数据挖掘
- python3
- 贝叶斯分类器

comments: true
---


## 1、贝叶斯分类实现（采用python3.6 数据集为arff文件格式）

数据挖掘课老师留的一个实现贝叶斯分类器的练习，数据源为arff格式的文件~下面是使用python语言编写的一个简单的实现案例。
<!-- more -->

## 1.1、 arff格式文件介绍

[参考链接](http://blog.sina.com.cn/s/blog_9d40b61301012xci.html)

> arff文件是Weka默认的储存数据集文件。每个arff文件对应一个二维表格。表格的各行是数据集的各实例，各列是数据集的各个属性。推荐使用`UltraEdit`这样的字符编辑软件或者**Sublime Text**这样的文本编译器查看arff文件的内容。

weather.arff 文件内容如下所示：
![arff.png-25.6kB][weather.arff]

识别ARFF文件的重要依据是分行，因此不能在这种文件里随意的断行。空行（或全是空格的行）将被忽略。
以“%”开始的行是注释，WEKA将忽略这些行。如果你看到的“weather.arff”文件多了或少了些“%”开始的行，是没有影响的。
除去注释后，整个ARFF文件可以分为两个部分。第一部分给出了头信息（Head information），包括了对关系的声明和对属性的声明。第二部分给出了数据信息（Data information），即数据集中给出的数据。从“@data”标记开始，后面的就是数据信息了。
虽然Weka也支持其他一些格式的文件，但是ARFF格式是支持的最好的。因此有必要在数据处理之前把数据集的格式转换成ARFF。

## 1.2、 arff格式文件读取

```python
import re  
import sys  
def readArff(fileName):  
    arffFile = open(fileName,'r')  
    data = []  
    for line in arffFile.readlines():  
        if not (line.startswith('@')):  
            if not (line.startswith('%')):  
                if line !='\n':  
                    L=line.strip('\n')  
                    k=L.split(',')  
                    data.append(k)                      
                    print(k)  
    print(data)  
if __name__ =='__main__':  
    fileName=r'C:\Users\Administrator\Desktop\exepirenment\classifill\data\weather.arff'  
    readArff(fileName)  
```

> 输出结果如下所示：
```
['sunny', '85', '85', 'FALSE', 'no']
['sunny', '80', '90', 'TRUE', 'no']
['overcast', '83', '86', 'FALSE', 'yes']
['rainy', '70', '96', 'FALSE', 'yes']
['rainy', '68', '80', 'FALSE', 'yes']
['rainy', '65', '70', 'TRUE', 'no']
['overcast', '64', '65', 'TRUE', 'yes']
['sunny', '72', '95', 'FALSE', 'no']
['sunny', '69', '70', 'FALSE', 'yes']
['rainy', '75', '80', 'FALSE', 'yes']
['sunny', '75', '70', 'TRUE', 'yes']
['overcast', '72', '90', 'TRUE', 'yes']
['overcast', '81', '75', 'FALSE', 'yes']
['rainy', '71', '91', 'TRUE', 'no']
[['sunny', '85', '85', 'FALSE', 'no'], ['sunny', '80', '90', 'TRUE', 'no'], ['overcast', '83', '86', 'FALSE', 'yes'], ['rainy', '70', '96', 'FALSE', 'yes'], ['rainy', '68', '80', 'FALSE', 'yes'], ['rainy', '65', '70', 'TRUE', 'no'], ['overcast', '64', '65', 'TRUE', 'yes'], ['sunny', '72', '95', 'FALSE', 'no'], ['sunny', '69', '70', 'FALSE', 'yes'], ['rainy', '75', '80', 'FALSE', 'yes'], ['sunny', '75', '70', 'TRUE', 'yes'], ['overcast', '72', '90', 'TRUE', 'yes'], ['overcast', '81', '75', 'FALSE', 'yes'], ['rainy', '71', '91', 'TRUE', 'no']]
```

## 1.3、 实现贝叶斯分类器
[***参考链接***](http://blog.csdn.net/ben_ben_niao/article/details/40951843)

```python
import re  
import sys  
import bisect  
data =[]  #全局变量  
def readArff(fileName):  
    arffFile = open(fileName,'r')  
    global data  
    for line in arffFile.readlines():  
        if not (line.startswith('@')):  
            if not (line.startswith('%')):  
                if line !='\n':  
                    L=line.strip('\n')  
                    k=L.split(',')  
                    data.append(k)  
def bayesion(testData):  
    class1=[]  
    class2=[]  
    global data  
    for item in data:  
        if item[len(item)-1] == 'yes':  
            class1.append(item)  
        else:  
            class2.append(item)  
    class1Probability = len(class1) /len(data)  
    class2Probability = len(class2) /len(data)  
    for i in range(len(testData)):  
        count = 0  
        for elem in class1:  
            if testData[i]==elem[i]:  
                count +=1       #统计个数  
        class1Probability *= count/len(class1) #累计乘法 求总概率  
        count = 0  
        for elem in class2:  
            if testData[i]==elem[i]:  
                count +=1  
        class2Probability *=count/len(class2)  
    if class1Probability >class2Probability: #比较，进而分类  
        print("The result is : Yes")  
    else:  
        print("The result if : No")  
#数据预处理，将data数据分箱，data数据为 list[list1,list2...]类型  
def dataPreprocessing1(data):  
    breakpoint1 =[70,80]  
    breakpoint2=[80,90]  
    newValue1='LMH'  
    for item in data:  
        i = bisect.bisect(breakpoint1,int(item[1])) #int(),str()等类型需要转换  
        item[1]=str(newValue1[i])  
        j = bisect.bisect(breakpoint2,int(item[2]))  
        item[2]=str(newValue1[j])  
#数据预处理，分箱，针对单个list数据，data为list['..','..']类型  
def dataPreprocessing2(data):  
    breakpoint1 =[70,80]  
    breakpoint2=[80,90]  
    newValue1='LMH'  
    i = bisect.bisect(breakpoint1,int(data[1]))  
    data[1]=str(newValue1[i])  
    j = bisect.bisect(breakpoint2,int(data[2]))  
    data[2]=str(newValue1[j])  
  
  
if __name__ =='__main__':  
    fileName=r'C:\Users\Administrator\Desktop\exepirenment\classifill\data\weather.arff'  
    readArff(fileName)  
    dataPreprocessing1(data)  
  
    testData =['overcast','72','80','TRUE']  
    dataPreprocessing2(testData)  
  
    bayesion(testData)  
```

  [weather.arff]: http://static.zybuluo.com/Heany/x557l6ij8dord89b0lyjfsom/arff.png