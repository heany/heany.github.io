<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Heany's blog"><title>Ubuntu 17.10配置Hadoop+Spark环境 | 知微</title><link rel="stylesheet" type="text/css" href="//fonts.neworld.org/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.1"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.1"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Ubuntu 17.10配置Hadoop+Spark环境</h1><a id="logo" href="/.">知微</a><p class="description">一盏灯，一个人，亮着的屏幕，游走的灵魂。!</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="Arama"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">Ubuntu 17.10配置Hadoop+Spark环境</h1><div class="post-meta"><a href="/2018/04/08/Ubuntu-17-10配置Hadoop-Spark环境/#comments" class="comment-count"><i id="changyan_count_unit" data-xid="2018/04/08/Ubuntu-17-10配置Hadoop-Spark环境/"></i>留言,<i id="changyan_parti_unit" data-xid="2018/04/08/Ubuntu-17-10配置Hadoop-Spark环境/"></i>参与</a><p><span class="date">Apr 08, 2018</span><span><a href="/categories/分布式与大数据/" class="category">分布式与大数据</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>&nbsp;&nbsp;最近导师带的项目是与大数据相关，感觉这几年大数据技术还挺火的，就想着也去学一下，丰富自己的技能栈。本文主要讲的是hadoop+spark的环境搭建,然后使用自带的examples测试环境，这里不涉及原理介绍。<a id="more"></a></p>
<h2 id="二、Hadoop的三种运行模式介绍"><a href="#二、Hadoop的三种运行模式介绍" class="headerlink" title="二、Hadoop的三种运行模式介绍"></a>二、Hadoop的三种运行模式介绍</h2><h3 id="2-1、-单机模式也叫独立模式（Local或Standalone-Mode）"><a href="#2-1、-单机模式也叫独立模式（Local或Standalone-Mode）" class="headerlink" title="2.1、 单机模式也叫独立模式（Local或Standalone Mode）"></a>2.1、 单机模式也叫独立模式（Local或Standalone Mode）</h3><ul>
<li>默认情况下，Hadoop即处于该模式，用于开发和调式。</li>
<li>不对配置文件进行修改。</li>
<li>使用本地文件系统，而不是分布式文件系统。</li>
<li>Hadoop不会启动NameNode、DataNode、JobTracker、TaskTracker等守护进程，Map()和Reduce()任务作为同一个进程的不同部分来执行的。</li>
<li>用于对MapReduce程序的逻辑进行调试，确保程序的正确。</li>
</ul>
<h3 id="2-2、-伪分布式模式（Pseudo-Distrubuted-Mode）"><a href="#2-2、-伪分布式模式（Pseudo-Distrubuted-Mode）" class="headerlink" title="2.2、 伪分布式模式（Pseudo-Distrubuted Mode）"></a>2.2、 伪分布式模式（Pseudo-Distrubuted Mode）</h3><ul>
<li>Hadoop的守护进程运行在本机机器上，模拟一个小规模的集群</li>
<li>在一台主机上模拟多主机。</li>
<li>Hadoop启动NameNode、DataNode、JobTracker、TaskTracker这些守护进程都在同一台机器上运行，是相互独立的Java进程。</li>
<li>在这种模式下，Hadoop使用的是分布式文件系统，各个作业也是由JobTraker服务，来管理的独立进程。在单机模式之上增加了代码调试功能，允许检查内存使用情况，HDFS输入输出，以及其他的守护进程交互。类似于完全分布式模式，因此，这种模式常用来开发测试Hadoop程序的执行是否正确。</li>
<li>修改3个配置文件：core-site.xml（Hadoop集群的特性，作用于全部进程及客户端）、hdfs-site.xml（配置HDFS集群的工作属性）、mapred-site.xml（配置MapReduce集群的属性）</li>
<li>格式化文件系统</li>
</ul>
<h3 id="2-3、-全分布式集群模式（Full-Distributed-Mode）"><a href="#2-3、-全分布式集群模式（Full-Distributed-Mode）" class="headerlink" title="2.3、 全分布式集群模式（Full-Distributed Mode）"></a>2.3、 全分布式集群模式（Full-Distributed Mode）</h3><ul>
<li>Hadoop的守护进程运行在一个集群上　</li>
<li>Hadoop的守护进程运行在由多台主机搭建的集群上，是真正的生产环境。</li>
<li>在所有的主机上安装JDK和Hadoop，组成相互连通的网络。</li>
<li>在主机间设置SSH免密码登录，把各从节点生成的公钥添加到主节点的信任列表。</li>
<li>修改3个配置文件：core-site.xml、hdfs-site.xml、mapred-site.xml，指定NameNode和JobTraker的位置和端口，设置文件的副本等参数</li>
<li>格式化文件系统。</li>
</ul>
<h2 id="三、搭建伪分布式集群的前提条件"><a href="#三、搭建伪分布式集群的前提条件" class="headerlink" title="三、搭建伪分布式集群的前提条件"></a>三、搭建伪分布式集群的前提条件</h2><h3 id="3-1、-实验环境"><a href="#3-1、-实验环境" class="headerlink" title="3.1、 实验环境"></a>3.1、 实验环境</h3><ul>
<li style="list-style: none"><input type="checkbox" checked> <strong>ubuntu 17.10-x64</strong></li>
<li style="list-style: none"><input type="checkbox" checked> <strong>jdk_1.8.0_162</strong></li>
<li style="list-style: none"><input type="checkbox" checked> <strong>Hadoop-3.0.0</strong></li>
<li style="list-style: none"><input type="checkbox" checked> <strong>Spark-2.3.0</strong></li>
</ul>
<h3 id="3-2、-安装JDK，并配置环境变量"><a href="#3-2、-安装JDK，并配置环境变量" class="headerlink" title="3.2、 安装JDK，并配置环境变量"></a>3.2、 安装JDK，并配置环境变量</h3><p>&nbsp;&nbsp;首先去官网下载对应系统版本的jdk,然后解压到<code>opt</code>目录下，命令如下：</p>
<blockquote>
<pre><code>sudo tar -zxvf jdk-8u162-linux-x64.tar.gz -C /opt
</code></pre></blockquote>
<p>然后切换到<code>/opt</code>目录下，修改jdk的文件夹命名</p>
<blockquote>
<pre><code>mv jdk-8u162-linux-x64 ./jdk
</code></pre></blockquote>
<p>最后，配置环境变量，</p>
<blockquote>
<pre><code>vim /etc/profile
</code></pre></blockquote>
<p>在配置文件中加入：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/jdk</span><br><span class="line">export JRE_HOME=$JAVA_HOME/jre</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure>
<p>使配置文件生效，执行下面的命令：</p>
<pre><code>source /etc/profile
</code></pre><p>最后查看是否安装成功</p>
<pre><code>java -version
</code></pre><h3 id="3-3、-安装Scala"><a href="#3-3、-安装Scala" class="headerlink" title="3.3、 安装Scala"></a>3.3、 安装Scala</h3><ul>
<li>官网下载scala(scala-2.12.4.tgz)</li>
<li><p>解压下载scala包</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo tar -xzvf scala<span class="number">-2.12</span><span class="number">.4</span>.tgz -C /opt/</span><br><span class="line"># 修改文件名：</span><br><span class="line">sudo mv scala<span class="number">-2.12</span><span class="number">.4</span> ./scala</span><br></pre></td></tr></table></figure>
</li>
<li><p>添加环境变量</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"><span class="comment"># 在后面添加下面内容</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">SCALA_HOME</span>=/opt/scala</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$SCALA_HOME</span>/bin:$PATH</span><br></pre></td></tr></table></figure>
</li>
<li><p>使配置生效并测试</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br><span class="line"><span class="comment"># 测试是否安装成功</span></span><br><span class="line">scala -version  # 输出scala版本号</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="3-4、-安装ssh并设置免密登录"><a href="#3-4、-安装ssh并设置免密登录" class="headerlink" title="3.4、 安装ssh并设置免密登录"></a>3.4、 安装ssh并设置免密登录</h3><ul>
<li><p>安装ssh。如果已安装则跳过这一步。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-<span class="builtin-name">get</span> install openssh-server</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置ssh无密登录</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa <span class="comment"># 然后一直回车</span></span><br><span class="line">cat ~<span class="regexp">/.ssh/id</span>_rsa.pub <span class="meta">&gt;&gt; </span>~<span class="regexp">/.ssh/authorized</span>_keys</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试ssh无密登录</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ssh</span> localhost</span><br><span class="line"><span class="comment"># 如果不提示输入密码则配置成功</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>[TOC]</p>
<h2 id="四、搭建伪分布式集群"><a href="#四、搭建伪分布式集群" class="headerlink" title="四、搭建伪分布式集群"></a>四、搭建伪分布式集群</h2><h3 id="4-1、-hadoop下载安装"><a href="#4-1、-hadoop下载安装" class="headerlink" title="4.1、 hadoop下载安装"></a>4.1、 hadoop下载安装</h3><ul>
<li>下载Hadoop(笔者下载的是hadoop-3.0.0.tar.gz)</li>
<li><p>解压并重命名</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解压</span></span><br><span class="line">sudo tar -xzvf hadoop-3.0.0.tar.gz -C <span class="string">/opt/</span></span><br><span class="line"><span class="comment"># 重命名</span></span><br><span class="line"><span class="keyword">cd</span> <span class="string">/opt</span></span><br><span class="line">sudo hadoop-3.0.0 hadoop</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改文件权限</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cd</span> <span class="string">/opt</span></span><br><span class="line">sudo chown -R yourname<span class="function">:yourname</span> hadoop  </span><br><span class="line"><span class="comment"># yourname替换成你的用户名  -R表示逐级往下授权</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>配置环境变量</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"><span class="comment"># 在最后添加下面代码</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_HOME</span>=/opt/hadoop</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_COMMON_LIB_NATIVE_DIR</span>=<span class="variable">$HADOOP_HOME</span>/lib/native</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_OPTS</span>=<span class="string">"-Djava.library.path=<span class="variable">$HADOOP_COMMON_LIB_NATIVE_DIR</span>"</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>使配置生效</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">source</span> <span class="regexp">/etc/</span>profile</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop <span class="built_in">version</span>  <span class="comment"># output the information of the version of the hadoop</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="4-2、-Hadoop伪分布式配置"><a href="#4-2、-Hadoop伪分布式配置" class="headerlink" title="4.2、 Hadoop伪分布式配置"></a>4.2、 Hadoop伪分布式配置</h3><ul>
<li><p>修改配置文件<code>hadoop-env.sh</code></p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换到工作目录</span></span><br><span class="line">cd /opt/hadoop/etc/hadoop</span><br><span class="line"><span class="comment"># 打开配置文件</span></span><br><span class="line">vim hadoop-env.sh</span><br><span class="line"><span class="comment"># 直接加上下面代码</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/opt/jdk</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改配置文件<code>core-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://219.223.243.131:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<blockquote>
<p>   219.223.243.131是我的节点所在主机的ip,9000为默认的端口，不用更改</p>
</blockquote>
<ul>
<li><p>修改配置文件<code>hdfs-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-cluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///data/hadoop/hdfs/nn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///data/hadoop/hdfs/snn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///data/hadoop/hdfs/snn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///data/hadoop/hdfs/dn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>修改配置文件<code>mapred-site.xml</code></p>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="params">&lt;property&gt;</span></span><br><span class="line">    <span class="params">&lt;name&gt;</span>mapreduce.framework.name<span class="params">&lt;/name&gt;</span></span><br><span class="line">    <span class="params">&lt;value&gt;</span>yarn<span class="params">&lt;/value&gt;</span></span><br><span class="line"><span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;property&gt;</span></span><br><span class="line">    <span class="params">&lt;name&gt;</span>mapreduce.admin.user.env<span class="params">&lt;/name&gt;</span></span><br><span class="line">    <span class="params">&lt;value&gt;</span>HADOOP_MAPRED_HOME=$HADOOP_HOME<span class="params">&lt;/value&gt;</span></span><br><span class="line"><span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;property&gt;</span></span><br><span class="line">    <span class="params">&lt;name&gt;</span>yarn.app.mapreduce.am.env<span class="params">&lt;/name&gt;</span></span><br><span class="line">    <span class="params">&lt;value&gt;</span>HADOOP_MAPRED_HOME=$HADOOP_HOME<span class="params">&lt;/value&gt;</span></span><br><span class="line"><span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;property&gt;</span></span><br><span class="line">    <span class="params">&lt;name&gt;</span>mapreduce.map.env<span class="params">&lt;/name&gt;</span></span><br><span class="line">    <span class="params">&lt;value&gt;</span>HADOOP_MAPRED_HOME=$HADOOP_HOME<span class="params">&lt;/value&gt;</span></span><br><span class="line"><span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;property&gt;</span></span><br><span class="line">    <span class="params">&lt;name&gt;</span>mapreduce.reduce.env<span class="params">&lt;/name&gt;</span></span><br><span class="line">    <span class="params">&lt;value&gt;</span>HADOOP_MAPRED_HOME=$HADOOP_HOME<span class="params">&lt;/value&gt;</span></span><br><span class="line"><span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;property&gt;</span></span><br><span class="line">    <span class="params">&lt;name&gt;</span>mapreduce.application.classpath<span class="params">&lt;/name&gt;</span></span><br><span class="line">    <span class="params">&lt;value&gt;</span></span><br><span class="line">         <span class="meta-keyword">/opt/</span>hadoop<span class="meta-keyword">/etc/</span>hadoop,</span><br><span class="line">         <span class="meta-keyword">/opt/</span>hadoop<span class="meta-keyword">/share/</span>hadoop<span class="meta-keyword">/common/</span>*,</span><br><span class="line">         <span class="meta-keyword">/opt/</span>hadoop<span class="meta-keyword">/share/</span>hadoop<span class="meta-keyword">/common/</span>lib<span class="comment">/*,</span></span><br><span class="line"><span class="comment">         /opt/hadoop/share/hadoop/hdfs/*,</span></span><br><span class="line"><span class="comment">         /opt/hadoop/share/hadoop/hdfs/lib/*,</span></span><br><span class="line"><span class="comment">         /opt/hadoop/share/hadoop/mapreduce/*,</span></span><br><span class="line"><span class="comment">         /opt/hadoop/share/hadoop/mapreduce/lib/*,</span></span><br><span class="line"><span class="comment">         /opt/hadoop/share/hadoop/yarn/*,</span></span><br><span class="line"><span class="comment">         /opt/hadoop/share/hadoop/yarn/lib/*</span></span><br><span class="line"><span class="comment">    &lt;/value&gt;</span></span><br><span class="line"><span class="comment">&lt;/property&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>修改配置文件<code>yarn-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定ResourceManager的地址--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>219.223.243.131<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定reducer获取数据的方式--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.local-dirs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///data/hadoop/yarn/nm<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>创建相关目录</p>
<figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">sudo</span> mkdir -p /<span class="class"><span class="keyword">data</span>/hadoop/hdfs/nn</span></span><br><span class="line"><span class="title">sudo</span> mkdir -p /<span class="class"><span class="keyword">data</span>/hadoop/hdfs/dn</span></span><br><span class="line"><span class="title">sudo</span> mkdir -p /<span class="class"><span class="keyword">data</span>/hadoop/hdfs/snn</span></span><br><span class="line"><span class="title">sudo</span> mkdir -p /<span class="class"><span class="keyword">data</span>/hadoop/yarn/nm</span></span><br><span class="line"><span class="meta"># 然后给这些目录设置读写权限，</span></span><br><span class="line"><span class="meta"># 如果使用当前的用户（非root用户）启动相关进程，`/data`必须具有相应的读写权限</span></span><br><span class="line"><span class="meta"># 给`/data`目录及其子目录设置读写权限。 -R 递归设置权限</span></span><br><span class="line"><span class="title">sudo</span> chmod -<span class="type">R</span> <span class="number">777</span> /<span class="class"><span class="keyword">data</span></span></span><br></pre></td></tr></table></figure>
</li>
<li><p>对HDFS集群进行格式化，HDFS集群是用来存储数据的</p>
<figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -<span class="built_in">format</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="4-3、-启动集群"><a href="#4-3、-启动集群" class="headerlink" title="4.3、 启动集群"></a>4.3、 启动集群</h3><ol>
<li><p>启动HDFS集群</p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动主节点</span></span><br><span class="line">hdfs <span class="comment">--daemon start namenode </span></span><br><span class="line"><span class="comment"># 启动从节点</span></span><br><span class="line">hdfs <span class="comment">--daemon start datanode </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证节点是否启动，输入一下命令</span></span><br><span class="line">jps <span class="comment"># 看是否出现namenode和datanode</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>启动YARN集群</p>
<figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 启动资源管理器</span></span><br><span class="line">yarn --daemon start resourcemanager</span><br><span class="line"><span class="meta"># 启动节点管理器</span></span><br><span class="line">yarn --daemon start nodemanager</span><br><span class="line"></span><br><span class="line"><span class="meta"># 验证是否启动，同样是采用`jps`命令，看是否出想相关进程</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>启动作业历史服务器</p>
<figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mapred --daemon start historyserver</span><br><span class="line"># 同样采用`jps`命令查看是否启动成功</span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS和YARN集群都有对应的WEB监控页面。</p>
<blockquote>
<p> HDFS: <a href="http://ip:9870" target="_blank" rel="noopener">http://ip:9870</a> 或者 localhost:9870</p>
</blockquote>
</li>
</ol>
<p><img src="https://wx2.sinaimg.cn/mw1024/e0db46edgy1fq6ro1zxiuj20so0pvq5f.jpg" alt="图片名称" align="center"></p>
<p><img src="https://wx2.sinaimg.cn/mw1024/e0db46edgy1fq6ro1u9z0j20sh0ntgmn.jpg" alt="图片名称" align="center"></p>
<blockquote>
<p> YARN: <a href="http://ip:8088" target="_blank" rel="noopener">http://ip:8088</a></p>
</blockquote>
<p><img src="https://wx4.sinaimg.cn/mw1024/e0db46edgy1fq6ro1zitoj21ag0gstbh.jpg" alt="图片名称" align="center"></p>
<ol start="5">
<li><p>HDFS集群的简单操作命令</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -<span class="keyword">ls</span> /   # 相当于<span class="keyword">shell</span>中的 <span class="keyword">ll</span></span><br><span class="line">hdfs dfsadmin -safemode leave  # 关闭安全模式</span><br><span class="line">hdfs dfs -<span class="built_in">mkdir</span> -<span class="keyword">p</span> /user/<span class="built_in">input</span>  # 在hdfs文件系统上级联创建文件/user/<span class="built_in">input</span>，</span><br></pre></td></tr></table></figure>
</li>
<li><p>YARN集群examples测试</p>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 计算PI值的作业</span></span><br><span class="line">yarn jar <span class="meta-keyword">/opt/</span>hadoop<span class="meta-keyword">/share/</span>hadoop<span class="meta-keyword">/mapreduce/</span>hadoop-mapreduce-examples-*.jar pi <span class="number">4</span> <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="meta"># wordcount例子</span></span><br><span class="line"><span class="meta"># 首先创建一个输入文件，并上传到hdfs文件系统上</span></span><br><span class="line">hdfs dfs -put input <span class="meta-keyword">/user/</span>heany</span><br><span class="line"><span class="meta"># 然后执行</span></span><br><span class="line">yarn jar <span class="meta-keyword">/opt/</span>hadoop<span class="meta-keyword">/share/</span>hadoop<span class="meta-keyword">/mapreduce/</span>hadoop-mapreduce-examples-*.jar wordcount input output</span><br><span class="line"><span class="meta"># 用命令行查看结果</span></span><br><span class="line">hdfs dfs -cat <span class="meta-keyword">/user/</span>output/part-r<span class="number">-00000</span></span><br><span class="line"><span class="meta"># 或者在网页上查看</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="五、-安装Spark"><a href="#五、-安装Spark" class="headerlink" title="五、 安装Spark"></a>五、 安装Spark</h2><h3 id="5-1、-下载安装Spark"><a href="#5-1、-下载安装Spark" class="headerlink" title="5.1、 下载安装Spark"></a>5.1、 下载安装Spark</h3><ul>
<li>下载Spark(笔者下载的是spark-2.3.0-bin-hadoop2.7.tgz)</li>
<li><p>解压下载的Spark包</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo tar -zxvf spark<span class="number">-2.3</span><span class="number">.0</span>-bin-hadoop2<span class="number">.7</span>.tgz -C /opt</span><br></pre></td></tr></table></figure>
</li>
<li><p>重命名</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换到工作目录</span></span><br><span class="line"><span class="keyword">cd</span> <span class="string">/opt</span></span><br><span class="line">sudo mv spark-2.3.0-bin-hadoop2.7 spark</span><br></pre></td></tr></table></figure>
</li>
<li><p>添加环境变量</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"><span class="comment"># 在最后添加下面的代码</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">SPARK_HOME</span>=/opt/spark</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$SPARK_HOME</span>/bin:$SPARK_HOME/sbin:$PATH</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改文件的权限</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cd</span> <span class="string">/opt</span></span><br><span class="line">sudo chown -R yourname<span class="function">:yourname</span> <span class="string">./spark</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="5-2、-修改配置文件"><a href="#5-2、-修改配置文件" class="headerlink" title="5.2、 修改配置文件"></a>5.2、 修改配置文件</h3><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 拷贝配置文件</span><br><span class="line"><span class="keyword">cd</span> /<span class="keyword">opt</span>/spark</span><br><span class="line"><span class="keyword">cp</span> ./<span class="keyword">conf</span>/spark-env.<span class="keyword">sh</span>.template ./<span class="keyword">conf</span>/spark-env.<span class="keyword">sh</span></span><br><span class="line"></span><br><span class="line"># 修改配置文件</span><br><span class="line"><span class="keyword">vim</span> ./<span class="keyword">conf</span>/spark-env.<span class="keyword">sh</span></span><br><span class="line"># 在最后添加下面的代码</span><br><span class="line">export SPARK_DIST_CLASSPATH=$(/<span class="keyword">opt</span>/hadoop/bin/hadoop classpath)</span><br><span class="line">export JAVA_HOME=/<span class="keyword">opt</span>/jdk</span><br></pre></td></tr></table></figure>
<h3 id="5-3、运行examples验证安装"><a href="#5-3、运行examples验证安装" class="headerlink" title="5.3、运行examples验证安装"></a>5.3、运行examples验证安装</h3><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta-keyword">/opt/</span>spark<span class="meta-keyword">/bin/</span>run-example SparkPi <span class="number">2</span>&gt;<span class="variable">&amp;1</span> | grep <span class="string">"Pi is roughly"</span></span><br><span class="line"><span class="meta"># output</span></span><br><span class="line"><span class="meta"># Pi is roughly 3.143635718178591</span></span><br></pre></td></tr></table></figure>
<h3 id="5-4、-脚本启动Hadoop和Spark"><a href="#5-4、-脚本启动Hadoop和Spark" class="headerlink" title="5.4、 脚本启动Hadoop和Spark"></a>5.4、 脚本启动Hadoop和Spark</h3><ul>
<li><p>启动spark</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/<span class="keyword">opt</span>/spark/sbin/start-<span class="keyword">all</span>.<span class="keyword">sh</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>通过WEB页面查看</p>
<blockquote>
<p> 浏览器输入地址：<a href="http://localhost:8080" target="_blank" rel="noopener">http://localhost:8080</a></p>
</blockquote>
</li>
<li><p>编写自动化脚本</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动Hadoop以及Spark脚本</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># 启动Hadoop以及yarn</span></span><br><span class="line">start-dfs.sh</span><br><span class="line">start-yarn.sh</span><br><span class="line"><span class="comment"># 启动历史服务器</span></span><br><span class="line"><span class="comment">#mr-jobhistory-daemon.sh start historyserver</span></span><br><span class="line">mapred --daemon start historyserver</span><br><span class="line"><span class="comment"># 启动Spark</span></span><br><span class="line">/opt/spark/sbin/start-all.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止Hadoop以及Spark脚本</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># 停止Hadoop以及yarn</span></span><br><span class="line">stop-dfs.sh</span><br><span class="line">stop-yarn.sh</span><br><span class="line"><span class="comment"># 停止历史服务器</span></span><br><span class="line"><span class="comment">#mr-jobhistory-daemon.sh stop historyserver</span></span><br><span class="line">mapred --daemon stop historyserver</span><br><span class="line"><span class="comment"># 停止Spark</span></span><br><span class="line">/opt/spark/sbin/stop-all.sh</span><br></pre></td></tr></table></figure></li>
</ul>
</div><div class="tags"><a href="/tags/Ubuntu-17-10-hadoop-Spark/">Ubuntu 17.10 hadoop Spark</a></div><div class="post-share"><div class="bdsharebuttonbox"><span style="float:left;line-height: 28px;height: 28px;font-size:16px;font-weight:blod">分享到：</span><a href="#" data-cmd="more" class="bds_more"></a><a href="#" data-cmd="mshare" title="分享到一键分享" class="bds_mshare"></a><a href="#" data-cmd="fbook" title="分享到Facebook" class="bds_fbook"></a><a href="#" data-cmd="twi" title="分享到Twitter" class="bds_twi"></a><a href="#" data-cmd="linkedin" title="分享到linkedin" class="bds_linkedin"></a><a href="#" data-cmd="youdao" title="分享到有道云笔记" class="bds_youdao"></a><a href="#" data-cmd="evernotecn" title="分享到印象笔记" class="bds_evernotecn"></a><a href="#" data-cmd="weixin" title="分享到微信" class="bds_weixin"></a><a href="#" data-cmd="qzone" title="分享到QQ空间" class="bds_qzone"></a><a href="#" data-cmd="tsina" title="分享到新浪微博" class="bds_tsina"></a></div></div><div class="post-nav"><a href="/2018/04/09/sublime-text-3-最新的注册码/" class="pre">sublime text 3 最新的注册码</a><a href="/2018/03/31/Shell-Script学习笔记/" class="next">Shell Script学习笔记</a></div><div id="comments"><div id="SOHUCS" sid="2018/04/08/Ubuntu-17-10配置Hadoop-Spark环境/"></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#一、前言"><span class="toc-text">一、前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二、Hadoop的三种运行模式介绍"><span class="toc-text">二、Hadoop的三种运行模式介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1、-单机模式也叫独立模式（Local或Standalone-Mode）"><span class="toc-text">2.1、 单机模式也叫独立模式（Local或Standalone Mode）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2、-伪分布式模式（Pseudo-Distrubuted-Mode）"><span class="toc-text">2.2、 伪分布式模式（Pseudo-Distrubuted Mode）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3、-全分布式集群模式（Full-Distributed-Mode）"><span class="toc-text">2.3、 全分布式集群模式（Full-Distributed Mode）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三、搭建伪分布式集群的前提条件"><span class="toc-text">三、搭建伪分布式集群的前提条件</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1、-实验环境"><span class="toc-text">3.1、 实验环境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2、-安装JDK，并配置环境变量"><span class="toc-text">3.2、 安装JDK，并配置环境变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3、-安装Scala"><span class="toc-text">3.3、 安装Scala</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4、-安装ssh并设置免密登录"><span class="toc-text">3.4、 安装ssh并设置免密登录</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#四、搭建伪分布式集群"><span class="toc-text">四、搭建伪分布式集群</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1、-hadoop下载安装"><span class="toc-text">4.1、 hadoop下载安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2、-Hadoop伪分布式配置"><span class="toc-text">4.2、 Hadoop伪分布式配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3、-启动集群"><span class="toc-text">4.3、 启动集群</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#五、-安装Spark"><span class="toc-text">五、 安装Spark</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1、-下载安装Spark"><span class="toc-text">5.1、 下载安装Spark</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2、-修改配置文件"><span class="toc-text">5.2、 修改配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3、运行examples验证安装"><span class="toc-text">5.3、运行examples验证安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4、-脚本启动Hadoop和Spark"><span class="toc-text">5.4、 脚本启动Hadoop和Spark</span></a></li></ol></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/02/02/golang基础学习/">golang基础学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/02/Redis学习笔记/">Redis学习笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/08/mysql操作使用变量作为表名/">mysql操作使用变量作为表名</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/06/Numpy的random函数汇总/">Numpy的random函数汇总</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/15/Nginx-PHP-MySQL搭建过程/">Nginx+PHP+MySQL搭建过程</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/14/TF-IDF理解/">TF-IDF理解</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/18/删除Github-com上repository中的某个文件夹/">删除Github.com上repository中的某个文件夹</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/16/Docker技术学习/">Docker技术学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/09/sublime-text-3-最新的注册码/">sublime text 3 最新的注册码</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/08/Ubuntu-17-10配置Hadoop-Spark环境/">Ubuntu 17.10配置Hadoop+Spark环境</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Github/">Github</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/MySQL/">MySQL</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Script/">Script</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Website/">Website</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/golang/">golang</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/其他/">其他</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/分布式与大数据/">分布式与大数据</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/常用工具/">常用工具</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/">技术</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/sublime-text-3-注册码/" style="font-size: 15px;">sublime-text-3 注册码</a> <a href="/tags/Nginx-php-MySQL/" style="font-size: 15px;">Nginx-php-MySQL</a> <a href="/tags/Numpy-Random/" style="font-size: 15px;">Numpy Random</a> <a href="/tags/TF-IDF-Algorithm/" style="font-size: 15px;">TF-IDF-Algorithm</a> <a href="/tags/golang/" style="font-size: 15px;">golang</a> <a href="/tags/hexo-Blog/" style="font-size: 15px;">hexo Blog</a> <a href="/tags/hexo常用命令/" style="font-size: 15px;">hexo常用命令</a> <a href="/tags/python学习笔记/" style="font-size: 15px;">python学习笔记</a> <a href="/tags/sublime插件/" style="font-size: 15px;">sublime插件</a> <a href="/tags/Markdown/" style="font-size: 15px;">Markdown</a> <a href="/tags/redis/" style="font-size: 15px;">redis</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/sublime-插件/" style="font-size: 15px;">sublime 插件</a> <a href="/tags/hexo-Github-Pages-Blog/" style="font-size: 15px;">hexo Github-Pages Blog</a> <a href="/tags/数据挖掘/" style="font-size: 15px;">数据挖掘</a> <a href="/tags/python3/" style="font-size: 15px;">python3</a> <a href="/tags/贝叶斯分类器/" style="font-size: 15px;">贝叶斯分类器</a> <a href="/tags/Ubuntu-17-10-hadoop-Spark/" style="font-size: 15px;">Ubuntu 17.10 hadoop Spark</a> <a href="/tags/Docker/" style="font-size: 15px;">Docker</a> <a href="/tags/Shell-linux/" style="font-size: 15px;">Shell linux</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="http://chaoo.oschina.io/" title="秋过冬漫长" target="_blank">秋过冬漫长</a><ul></ul><a href="https://github.com/chaooo/hexo-theme-BlueLake" title="BlueLake主题" target="_blank">BlueLake主题</a><ul></ul><a href="zhiwei.space" title="知微" target="_blank">知微</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">Baidu Site Haritası</a> |  <a href="/atom.xml">订阅</a> |  <a href="/about/">关于</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次</p><p><span> Copyright &copy;<a href="/." rel="nofollow">Heany.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.1"></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.1" async></script><script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":["mshare","weixin","tsina","qzone","linkedin","fbook","twi","print","renren","sqq","evernotecn","bdysc","tqq","tqf","bdxc","kaixin001","tieba","douban","bdhome","thx","ibaidu","meilishuo","mogujie","diandian","huaban","duitang","hx","fx","youdao","sdo","qingbiji","people","xinhua","mail","isohu","yaolan","wealink","ty","iguba","h163","copy"],"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"]}};with(document)0[(getElementsByTagName('head')[0]||head).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script><script>window._config = { showScore: true };
(function(){ 
  var appid = 'cytgrjtsE## 畅言(appid)'; 
  var conf = '2d7d1ad1a462dac6cba991107b06dad2##畅言(appkey)'; 
  var width = window.innerWidth || document.documentElement.clientWidth; 
  var nodes =document.getElementsByTagName("head")[0]||document.head||document.documentElement;
  if (/(Android|iPhone|iPad|iPod|iOS)/i.test(navigator.userAgent) && width < 750) {  
      window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=' + appid + '&conf=' + conf + '"><\/script>');
  }
  else { 
    var loadJs=function(d,a){
      var b=document.createElement("script");b.setAttribute("type","text/javascript");
      b.setAttribute("charset","UTF-8");
      b.setAttribute("src",d);
      if(typeof a==="function"){if(window.attachEvent){b.onreadystatechange=function(){var e=b.readyState;if(e==="loaded"||e==="complete"){b.onreadystatechange=null;a()}}}else{b.onload=a}}
      nodes.appendChild(b)
    };
    loadJs("https://changyan.sohu.com/upload/changyan.js",function(){window.changyan.api.config({appid:appid,conf:conf})}); 
  } 
  var loadCss = function(cssString){  
    var style=document.createElement("style");  
    style.setAttribute("type", "text/css");  
    if(style.styleSheet){// IE  
        style.styleSheet.cssText = cssString;  
    } else {// w3c  
        var cssText = document.createTextNode(cssString);  
        style.appendChild(cssText);  
    }
    nodes.appendChild(style);
  }
  window.onload=function(){loadCss('.module-hot-topic,.module-cmt-float-bar{display:none!important}#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w .wrap-action-w .cbox-prompt-w span.prompt-empty-w,#SOHUCS #SOHU_MAIN .module-cmt-float-bar .wrap-cont-w .cont-form-w .form-text-w span.text-null,#SOHUCS #SOHU_MAIN .module-cmt-float-bar .wrap-cont-w .cont-minwidth-w div.cont-comment-w a.comment-link-w,#SOHUCS #SOHU_MAIN .module-cmt-float-bar .wrap-cont-w .cont-minwidth-w div.cont-comment-w span.comment-text-w,#SOHUCS #SOHU_MAIN .module-cmt-footer .section-service-w div.service-wrap-w a:hover,#SOHUCS #SOHU_MAIN .module-cmt-header .section-cbox-w .block-head-w div.header-login,#SOHUCS #SOHU_MAIN .module-cmt-header .section-title-w .title-user-w .user-wrap-w span.wrap-name-w,#SOHUCS #SOHU_MAIN .module-cmt-list .action-click-gw span.click-disable-eg a em.icon-name-bg,#SOHUCS #SOHU_MAIN .module-cmt-list .block-title-gw ul li div.title-name-gw,#SOHUCS #SOHU_MAIN .module-cmt-list .cmt-list-type .cmt-list-number .comment-number span.cy-number,#SOHUCS #SOHU_MAIN .module-cmt-list .cmt-list-type .cmt-list-number span.comment-number,#SOHUCS #SOHU_MAIN .module-cmt-list .cmt-list-type .type-lists li.active,#SOHUCS #SOHU_MAIN .module-cmt-list .msg-wrap-gw .wrap-action-gw .action-click-gw span a:hover,#SOHUCS #SOHU_MAIN .module-cmt-list .picture-box-gw div.box-action-gw a:hover,#SOHUCS #SOHU_MAIN .module-cmt-list .wrap-action-gw .action-click-gw span a:hover em.icon-name-bg,#SOHUCS #SOHU_MAIN .module-cmt-list .wrap-user-gw span.user-name-gw a{color:#40759b!important}#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w .post-wrap-border-t div.post-wrap-border-t-r,#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w div.post-wrap-border-l,#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w div.post-wrap-border-r{display:none!important}#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w .post-wrap-border-t div.post-wrap-border-t-l{background:#FFF!important;top:-2px!important}#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w .wrap-action-w .action-function-w .uploading-wrapper-dw div.wrapper-image-dw,#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w div.post-wrap-main,#SOHUCS #SOHU_MAIN .module-cmt-float-bar .wrap-cont-w .cont-form-w div.form-text-w,#SOHUCS #SOHU_MAIN .module-cmt-header .section-cbox-w .block-head-w div.header-login,#SOHUCS #SOHU_MAIN .module-cmt-list .module-cmt-box .post-wrap-w div.post-wrap-main{border:1px solid #e6e6e6!important;border-radius:20px 20px 20px 20px;margin:0!important}#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w .wrap-action-w .action-issue-w .issue-btn-w a .btn-fw{width:130px!important;height:34px!important;line-height:33px!important;font-size:17px!important;background:#5483b1!important;border-radius:20px!important;color:#FFF!important;-webkit-box-shadow:0 -1px 4px #5483b1 inset;box-shadow:0 -1px 10px #5483b1 inset}#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w .wrap-action-w .action-issue-w .issue-btn-w a .btn-fw:before{content:"发表评论"}#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w .wrap-action-w .action-issue-w .issue-btn-w a:hover .btn-fw{color:#40759b!important;background:#FFF!important}#SOHUCS #SOHU_MAIN .module-cmt-list .cmt-list-type .type-lists li{background:none!important;border-bottom:1px solid #e6e6e6}#SOHUCS #SOHU_MAIN .module-cmt-list .cmt-list-type .type-lists li.active{border:1px solid #e6e6e6;border-radius:10px 10px 0 0;border-bottom:none}#SOHUCS #SOHU_MAIN .module-cmt-list .block-title-gw ul li .title-name-gw div.title-name-gw-tag{background:#5483b1!important;border-radius:3px}#SOHUCS #SOHU_MAIN .module-cmt-list .cmt-list-type div.cmt-list-border{background-color:#e6e6e6!important}#SOHUCS #SOHU_MAIN .module-cmt-notice ul.nt-list li.nt-item{border:1px solid #e6e6e6!important}#SOHUCS #SOHU_MAIN .module-cmt-notice ul.nt-list li.nt-item .nt-logo{text-align:center;line-height:40px;border-radius:50%!important;background:#e6e6e6!important}#SOHUCS #SOHU_MAIN .module-cmt-notice ul.nt-list li.nt-item .nt-logo:before{content:"畅";font-size:22px;color:#FFF}#SOHUCS #SOHU_MAIN .module-cmt-notice ul.nt-list li.nt-item a.nt-text,#SOHUCS #SOHU_MAIN .module-cmt-notice ul.nt-list li.nt-item a.nt-text i{color:#5483b1!important}#SOHUCS #SOHU_MAIN .module-cmt-header .section-title-w .title-user-w .user-wrap-w{background:#FFF!important}');};
})();</script><script src="https://assets.changyan.sohu.com/upload/plugins/plugins.count.js"></script></body></html>