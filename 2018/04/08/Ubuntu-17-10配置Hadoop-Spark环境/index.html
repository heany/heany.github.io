<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>Ubuntu 17.10配置Hadoop+Spark环境 | 知微</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="一、前言&amp;nbsp;&amp;nbsp;最近导师带的项目是与大数据相关，感觉这几年大数据技术还挺火的，就想着也去学一下，丰富自己的技能栈。本文主要讲的是hadoop+spark的环境搭建,然后使用自带的examples测试环境，这里不涉及原理介绍。">
<meta name="keywords" content="Ubuntu 17.10 hadoop Spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Ubuntu 17.10配置Hadoop+Spark环境">
<meta property="og:url" content="http://heany.github.io/2018/04/08/Ubuntu-17-10配置Hadoop-Spark环境/index.html">
<meta property="og:site_name" content="知微">
<meta property="og:description" content="一、前言&amp;nbsp;&amp;nbsp;最近导师带的项目是与大数据相关，感觉这几年大数据技术还挺火的，就想着也去学一下，丰富自己的技能栈。本文主要讲的是hadoop+spark的环境搭建,然后使用自带的examples测试环境，这里不涉及原理介绍。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://wx2.sinaimg.cn/mw1024/e0db46edgy1fq6ro1zxiuj20so0pvq5f.jpg">
<meta property="og:image" content="https://wx2.sinaimg.cn/mw1024/e0db46edgy1fq6ro1u9z0j20sh0ntgmn.jpg">
<meta property="og:image" content="https://wx4.sinaimg.cn/mw1024/e0db46edgy1fq6ro1zitoj21ag0gstbh.jpg">
<meta property="og:updated_time" content="2019-01-26T14:47:30.578Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Ubuntu 17.10配置Hadoop+Spark环境">
<meta name="twitter:description" content="一、前言&amp;nbsp;&amp;nbsp;最近导师带的项目是与大数据相关，感觉这几年大数据技术还挺火的，就想着也去学一下，丰富自己的技能栈。本文主要讲的是hadoop+spark的环境搭建,然后使用自带的examples测试环境，这里不涉及原理介绍。">
<meta name="twitter:image" content="https://wx2.sinaimg.cn/mw1024/e0db46edgy1fq6ro1zxiuj20so0pvq5f.jpg">
  
    <link rel="alternate" href="/atom.xml" title="知微" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">知微</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">一盏灯，一个人，亮着的屏幕，游走的灵魂。!</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://heany.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Ubuntu-17-10配置Hadoop-Spark环境" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/08/Ubuntu-17-10配置Hadoop-Spark环境/" class="article-date">
  <time datetime="2018-04-08T06:39:34.000Z" itemprop="datePublished">2018-04-08</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/分布式与大数据/">分布式与大数据</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Ubuntu 17.10配置Hadoop+Spark环境
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>&nbsp;&nbsp;最近导师带的项目是与大数据相关，感觉这几年大数据技术还挺火的，就想着也去学一下，丰富自己的技能栈。本文主要讲的是hadoop+spark的环境搭建,然后使用自带的examples测试环境，这里不涉及原理介绍。<a id="more"></a></p>
<h2 id="二、Hadoop的三种运行模式介绍"><a href="#二、Hadoop的三种运行模式介绍" class="headerlink" title="二、Hadoop的三种运行模式介绍"></a>二、Hadoop的三种运行模式介绍</h2><h3 id="2-1、-单机模式也叫独立模式（Local或Standalone-Mode）"><a href="#2-1、-单机模式也叫独立模式（Local或Standalone-Mode）" class="headerlink" title="2.1、 单机模式也叫独立模式（Local或Standalone Mode）"></a>2.1、 单机模式也叫独立模式（Local或Standalone Mode）</h3><ul>
<li>默认情况下，Hadoop即处于该模式，用于开发和调式。</li>
<li>不对配置文件进行修改。</li>
<li>使用本地文件系统，而不是分布式文件系统。</li>
<li>Hadoop不会启动NameNode、DataNode、JobTracker、TaskTracker等守护进程，Map()和Reduce()任务作为同一个进程的不同部分来执行的。</li>
<li>用于对MapReduce程序的逻辑进行调试，确保程序的正确。</li>
</ul>
<h3 id="2-2、-伪分布式模式（Pseudo-Distrubuted-Mode）"><a href="#2-2、-伪分布式模式（Pseudo-Distrubuted-Mode）" class="headerlink" title="2.2、 伪分布式模式（Pseudo-Distrubuted Mode）"></a>2.2、 伪分布式模式（Pseudo-Distrubuted Mode）</h3><ul>
<li>Hadoop的守护进程运行在本机机器上，模拟一个小规模的集群</li>
<li>在一台主机上模拟多主机。</li>
<li>Hadoop启动NameNode、DataNode、JobTracker、TaskTracker这些守护进程都在同一台机器上运行，是相互独立的Java进程。</li>
<li>在这种模式下，Hadoop使用的是分布式文件系统，各个作业也是由JobTraker服务，来管理的独立进程。在单机模式之上增加了代码调试功能，允许检查内存使用情况，HDFS输入输出，以及其他的守护进程交互。类似于完全分布式模式，因此，这种模式常用来开发测试Hadoop程序的执行是否正确。</li>
<li>修改3个配置文件：core-site.xml（Hadoop集群的特性，作用于全部进程及客户端）、hdfs-site.xml（配置HDFS集群的工作属性）、mapred-site.xml（配置MapReduce集群的属性）</li>
<li>格式化文件系统</li>
</ul>
<h3 id="2-3、-全分布式集群模式（Full-Distributed-Mode）"><a href="#2-3、-全分布式集群模式（Full-Distributed-Mode）" class="headerlink" title="2.3、 全分布式集群模式（Full-Distributed Mode）"></a>2.3、 全分布式集群模式（Full-Distributed Mode）</h3><ul>
<li>Hadoop的守护进程运行在一个集群上　</li>
<li>Hadoop的守护进程运行在由多台主机搭建的集群上，是真正的生产环境。</li>
<li>在所有的主机上安装JDK和Hadoop，组成相互连通的网络。</li>
<li>在主机间设置SSH免密码登录，把各从节点生成的公钥添加到主节点的信任列表。</li>
<li>修改3个配置文件：core-site.xml、hdfs-site.xml、mapred-site.xml，指定NameNode和JobTraker的位置和端口，设置文件的副本等参数</li>
<li>格式化文件系统。</li>
</ul>
<h2 id="三、搭建伪分布式集群的前提条件"><a href="#三、搭建伪分布式集群的前提条件" class="headerlink" title="三、搭建伪分布式集群的前提条件"></a>三、搭建伪分布式集群的前提条件</h2><h3 id="3-1、-实验环境"><a href="#3-1、-实验环境" class="headerlink" title="3.1、 实验环境"></a>3.1、 实验环境</h3><ul>
<li style="list-style: none"><input type="checkbox" checked> <strong>ubuntu 17.10-x64</strong></li>
<li style="list-style: none"><input type="checkbox" checked> <strong>jdk_1.8.0_162</strong></li>
<li style="list-style: none"><input type="checkbox" checked> <strong>Hadoop-3.0.0</strong></li>
<li style="list-style: none"><input type="checkbox" checked> <strong>Spark-2.3.0</strong></li>
</ul>
<h3 id="3-2、-安装JDK，并配置环境变量"><a href="#3-2、-安装JDK，并配置环境变量" class="headerlink" title="3.2、 安装JDK，并配置环境变量"></a>3.2、 安装JDK，并配置环境变量</h3><p>&nbsp;&nbsp;首先去官网下载对应系统版本的jdk,然后解压到<code>opt</code>目录下，命令如下：</p>
<blockquote>
<pre><code>sudo tar -zxvf jdk-8u162-linux-x64.tar.gz -C /opt
</code></pre></blockquote>
<p>然后切换到<code>/opt</code>目录下，修改jdk的文件夹命名</p>
<blockquote>
<pre><code>mv jdk-8u162-linux-x64 ./jdk
</code></pre></blockquote>
<p>最后，配置环境变量，</p>
<blockquote>
<pre><code>vim /etc/profile
</code></pre></blockquote>
<p>在配置文件中加入：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/jdk</span><br><span class="line">export JRE_HOME=$JAVA_HOME/jre</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure>
<p>使配置文件生效，执行下面的命令：</p>
<pre><code>source /etc/profile
</code></pre><p>最后查看是否安装成功</p>
<pre><code>java -version
</code></pre><h3 id="3-3、-安装Scala"><a href="#3-3、-安装Scala" class="headerlink" title="3.3、 安装Scala"></a>3.3、 安装Scala</h3><ul>
<li>官网下载scala(scala-2.12.4.tgz)</li>
<li><p>解压下载scala包</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo tar -xzvf scala<span class="number">-2.12</span><span class="number">.4</span>.tgz -C /opt/</span><br><span class="line"># 修改文件名：</span><br><span class="line">sudo mv scala<span class="number">-2.12</span><span class="number">.4</span> ./scala</span><br></pre></td></tr></table></figure>
</li>
<li><p>添加环境变量</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"><span class="comment"># 在后面添加下面内容</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">SCALA_HOME</span>=/opt/scala</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$SCALA_HOME</span>/bin:$PATH</span><br></pre></td></tr></table></figure>
</li>
<li><p>使配置生效并测试</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br><span class="line"><span class="comment"># 测试是否安装成功</span></span><br><span class="line">scala -version  # 输出scala版本号</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="3-4、-安装ssh并设置免密登录"><a href="#3-4、-安装ssh并设置免密登录" class="headerlink" title="3.4、 安装ssh并设置免密登录"></a>3.4、 安装ssh并设置免密登录</h3><ul>
<li><p>安装ssh。如果已安装则跳过这一步。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-<span class="builtin-name">get</span> install openssh-server</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置ssh无密登录</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa <span class="comment"># 然后一直回车</span></span><br><span class="line">cat ~<span class="regexp">/.ssh/id</span>_rsa.pub <span class="meta">&gt;&gt; </span>~<span class="regexp">/.ssh/authorized</span>_keys</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试ssh无密登录</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ssh</span> localhost</span><br><span class="line"><span class="comment"># 如果不提示输入密码则配置成功</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>[TOC]</p>
<h2 id="四、搭建伪分布式集群"><a href="#四、搭建伪分布式集群" class="headerlink" title="四、搭建伪分布式集群"></a>四、搭建伪分布式集群</h2><h3 id="4-1、-hadoop下载安装"><a href="#4-1、-hadoop下载安装" class="headerlink" title="4.1、 hadoop下载安装"></a>4.1、 hadoop下载安装</h3><ul>
<li>下载Hadoop(笔者下载的是hadoop-3.0.0.tar.gz)</li>
<li><p>解压并重命名</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解压</span></span><br><span class="line">sudo tar -xzvf hadoop-3.0.0.tar.gz -C <span class="string">/opt/</span></span><br><span class="line"><span class="comment"># 重命名</span></span><br><span class="line"><span class="keyword">cd</span> <span class="string">/opt</span></span><br><span class="line">sudo hadoop-3.0.0 hadoop</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改文件权限</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cd</span> <span class="string">/opt</span></span><br><span class="line">sudo chown -R yourname<span class="function">:yourname</span> hadoop  </span><br><span class="line"><span class="comment"># yourname替换成你的用户名  -R表示逐级往下授权</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>配置环境变量</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"><span class="comment"># 在最后添加下面代码</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_HOME</span>=/opt/hadoop</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_COMMON_LIB_NATIVE_DIR</span>=<span class="variable">$HADOOP_HOME</span>/lib/native</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_OPTS</span>=<span class="string">"-Djava.library.path=<span class="variable">$HADOOP_COMMON_LIB_NATIVE_DIR</span>"</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>使配置生效</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">source</span> <span class="regexp">/etc/</span>profile</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop <span class="built_in">version</span>  <span class="comment"># output the information of the version of the hadoop</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="4-2、-Hadoop伪分布式配置"><a href="#4-2、-Hadoop伪分布式配置" class="headerlink" title="4.2、 Hadoop伪分布式配置"></a>4.2、 Hadoop伪分布式配置</h3><ul>
<li><p>修改配置文件<code>hadoop-env.sh</code></p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换到工作目录</span></span><br><span class="line">cd /opt/hadoop/etc/hadoop</span><br><span class="line"><span class="comment"># 打开配置文件</span></span><br><span class="line">vim hadoop-env.sh</span><br><span class="line"><span class="comment"># 直接加上下面代码</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/opt/jdk</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改配置文件<code>core-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://219.223.243.131:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<blockquote>
<p>   219.223.243.131是我的节点所在主机的ip,9000为默认的端口，不用更改</p>
</blockquote>
<ul>
<li><p>修改配置文件<code>hdfs-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-cluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///data/hadoop/hdfs/nn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///data/hadoop/hdfs/snn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///data/hadoop/hdfs/snn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///data/hadoop/hdfs/dn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>修改配置文件<code>mapred-site.xml</code></p>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="params">&lt;property&gt;</span></span><br><span class="line">    <span class="params">&lt;name&gt;</span>mapreduce.framework.name<span class="params">&lt;/name&gt;</span></span><br><span class="line">    <span class="params">&lt;value&gt;</span>yarn<span class="params">&lt;/value&gt;</span></span><br><span class="line"><span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;property&gt;</span></span><br><span class="line">    <span class="params">&lt;name&gt;</span>mapreduce.admin.user.env<span class="params">&lt;/name&gt;</span></span><br><span class="line">    <span class="params">&lt;value&gt;</span>HADOOP_MAPRED_HOME=$HADOOP_HOME<span class="params">&lt;/value&gt;</span></span><br><span class="line"><span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;property&gt;</span></span><br><span class="line">    <span class="params">&lt;name&gt;</span>yarn.app.mapreduce.am.env<span class="params">&lt;/name&gt;</span></span><br><span class="line">    <span class="params">&lt;value&gt;</span>HADOOP_MAPRED_HOME=$HADOOP_HOME<span class="params">&lt;/value&gt;</span></span><br><span class="line"><span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;property&gt;</span></span><br><span class="line">    <span class="params">&lt;name&gt;</span>mapreduce.map.env<span class="params">&lt;/name&gt;</span></span><br><span class="line">    <span class="params">&lt;value&gt;</span>HADOOP_MAPRED_HOME=$HADOOP_HOME<span class="params">&lt;/value&gt;</span></span><br><span class="line"><span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;property&gt;</span></span><br><span class="line">    <span class="params">&lt;name&gt;</span>mapreduce.reduce.env<span class="params">&lt;/name&gt;</span></span><br><span class="line">    <span class="params">&lt;value&gt;</span>HADOOP_MAPRED_HOME=$HADOOP_HOME<span class="params">&lt;/value&gt;</span></span><br><span class="line"><span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;property&gt;</span></span><br><span class="line">    <span class="params">&lt;name&gt;</span>mapreduce.application.classpath<span class="params">&lt;/name&gt;</span></span><br><span class="line">    <span class="params">&lt;value&gt;</span></span><br><span class="line">         <span class="meta-keyword">/opt/</span>hadoop<span class="meta-keyword">/etc/</span>hadoop,</span><br><span class="line">         <span class="meta-keyword">/opt/</span>hadoop<span class="meta-keyword">/share/</span>hadoop<span class="meta-keyword">/common/</span>*,</span><br><span class="line">         <span class="meta-keyword">/opt/</span>hadoop<span class="meta-keyword">/share/</span>hadoop<span class="meta-keyword">/common/</span>lib<span class="comment">/*,</span></span><br><span class="line"><span class="comment">         /opt/hadoop/share/hadoop/hdfs/*,</span></span><br><span class="line"><span class="comment">         /opt/hadoop/share/hadoop/hdfs/lib/*,</span></span><br><span class="line"><span class="comment">         /opt/hadoop/share/hadoop/mapreduce/*,</span></span><br><span class="line"><span class="comment">         /opt/hadoop/share/hadoop/mapreduce/lib/*,</span></span><br><span class="line"><span class="comment">         /opt/hadoop/share/hadoop/yarn/*,</span></span><br><span class="line"><span class="comment">         /opt/hadoop/share/hadoop/yarn/lib/*</span></span><br><span class="line"><span class="comment">    &lt;/value&gt;</span></span><br><span class="line"><span class="comment">&lt;/property&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>修改配置文件<code>yarn-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定ResourceManager的地址--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>219.223.243.131<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定reducer获取数据的方式--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.local-dirs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///data/hadoop/yarn/nm<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>创建相关目录</p>
<figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">sudo</span> mkdir -p /<span class="class"><span class="keyword">data</span>/hadoop/hdfs/nn</span></span><br><span class="line"><span class="title">sudo</span> mkdir -p /<span class="class"><span class="keyword">data</span>/hadoop/hdfs/dn</span></span><br><span class="line"><span class="title">sudo</span> mkdir -p /<span class="class"><span class="keyword">data</span>/hadoop/hdfs/snn</span></span><br><span class="line"><span class="title">sudo</span> mkdir -p /<span class="class"><span class="keyword">data</span>/hadoop/yarn/nm</span></span><br><span class="line"><span class="meta"># 然后给这些目录设置读写权限，</span></span><br><span class="line"><span class="meta"># 如果使用当前的用户（非root用户）启动相关进程，`/data`必须具有相应的读写权限</span></span><br><span class="line"><span class="meta"># 给`/data`目录及其子目录设置读写权限。 -R 递归设置权限</span></span><br><span class="line"><span class="title">sudo</span> chmod -<span class="type">R</span> <span class="number">777</span> /<span class="class"><span class="keyword">data</span></span></span><br></pre></td></tr></table></figure>
</li>
<li><p>对HDFS集群进行格式化，HDFS集群是用来存储数据的</p>
<figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -<span class="built_in">format</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="4-3、-启动集群"><a href="#4-3、-启动集群" class="headerlink" title="4.3、 启动集群"></a>4.3、 启动集群</h3><ol>
<li><p>启动HDFS集群</p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动主节点</span></span><br><span class="line">hdfs <span class="comment">--daemon start namenode </span></span><br><span class="line"><span class="comment"># 启动从节点</span></span><br><span class="line">hdfs <span class="comment">--daemon start datanode </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证节点是否启动，输入一下命令</span></span><br><span class="line">jps <span class="comment"># 看是否出现namenode和datanode</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>启动YARN集群</p>
<figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 启动资源管理器</span></span><br><span class="line">yarn --daemon start resourcemanager</span><br><span class="line"><span class="meta"># 启动节点管理器</span></span><br><span class="line">yarn --daemon start nodemanager</span><br><span class="line"></span><br><span class="line"><span class="meta"># 验证是否启动，同样是采用`jps`命令，看是否出想相关进程</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>启动作业历史服务器</p>
<figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mapred --daemon start historyserver</span><br><span class="line"># 同样采用`jps`命令查看是否启动成功</span><br></pre></td></tr></table></figure>
</li>
<li><p>HDFS和YARN集群都有对应的WEB监控页面。</p>
<blockquote>
<p> HDFS: <a href="http://ip:9870" target="_blank" rel="noopener">http://ip:9870</a> 或者 localhost:9870</p>
</blockquote>
</li>
</ol>
<p><img src="https://wx2.sinaimg.cn/mw1024/e0db46edgy1fq6ro1zxiuj20so0pvq5f.jpg" alt="图片名称" align="center"></p>
<p><img src="https://wx2.sinaimg.cn/mw1024/e0db46edgy1fq6ro1u9z0j20sh0ntgmn.jpg" alt="图片名称" align="center"></p>
<blockquote>
<p> YARN: <a href="http://ip:8088" target="_blank" rel="noopener">http://ip:8088</a></p>
</blockquote>
<p><img src="https://wx4.sinaimg.cn/mw1024/e0db46edgy1fq6ro1zitoj21ag0gstbh.jpg" alt="图片名称" align="center"></p>
<ol start="5">
<li><p>HDFS集群的简单操作命令</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -<span class="keyword">ls</span> /   # 相当于<span class="keyword">shell</span>中的 <span class="keyword">ll</span></span><br><span class="line">hdfs dfsadmin -safemode leave  # 关闭安全模式</span><br><span class="line">hdfs dfs -<span class="built_in">mkdir</span> -<span class="keyword">p</span> /user/<span class="built_in">input</span>  # 在hdfs文件系统上级联创建文件/user/<span class="built_in">input</span>，</span><br></pre></td></tr></table></figure>
</li>
<li><p>YARN集群examples测试</p>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 计算PI值的作业</span></span><br><span class="line">yarn jar <span class="meta-keyword">/opt/</span>hadoop<span class="meta-keyword">/share/</span>hadoop<span class="meta-keyword">/mapreduce/</span>hadoop-mapreduce-examples-*.jar pi <span class="number">4</span> <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="meta"># wordcount例子</span></span><br><span class="line"><span class="meta"># 首先创建一个输入文件，并上传到hdfs文件系统上</span></span><br><span class="line">hdfs dfs -put input <span class="meta-keyword">/user/</span>heany</span><br><span class="line"><span class="meta"># 然后执行</span></span><br><span class="line">yarn jar <span class="meta-keyword">/opt/</span>hadoop<span class="meta-keyword">/share/</span>hadoop<span class="meta-keyword">/mapreduce/</span>hadoop-mapreduce-examples-*.jar wordcount input output</span><br><span class="line"><span class="meta"># 用命令行查看结果</span></span><br><span class="line">hdfs dfs -cat <span class="meta-keyword">/user/</span>output/part-r<span class="number">-00000</span></span><br><span class="line"><span class="meta"># 或者在网页上查看</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="五、-安装Spark"><a href="#五、-安装Spark" class="headerlink" title="五、 安装Spark"></a>五、 安装Spark</h2><h3 id="5-1、-下载安装Spark"><a href="#5-1、-下载安装Spark" class="headerlink" title="5.1、 下载安装Spark"></a>5.1、 下载安装Spark</h3><ul>
<li>下载Spark(笔者下载的是spark-2.3.0-bin-hadoop2.7.tgz)</li>
<li><p>解压下载的Spark包</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo tar -zxvf spark<span class="number">-2.3</span><span class="number">.0</span>-bin-hadoop2<span class="number">.7</span>.tgz -C /opt</span><br></pre></td></tr></table></figure>
</li>
<li><p>重命名</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换到工作目录</span></span><br><span class="line"><span class="keyword">cd</span> <span class="string">/opt</span></span><br><span class="line">sudo mv spark-2.3.0-bin-hadoop2.7 spark</span><br></pre></td></tr></table></figure>
</li>
<li><p>添加环境变量</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"><span class="comment"># 在最后添加下面的代码</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">SPARK_HOME</span>=/opt/spark</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$SPARK_HOME</span>/bin:$SPARK_HOME/sbin:$PATH</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改文件的权限</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cd</span> <span class="string">/opt</span></span><br><span class="line">sudo chown -R yourname<span class="function">:yourname</span> <span class="string">./spark</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="5-2、-修改配置文件"><a href="#5-2、-修改配置文件" class="headerlink" title="5.2、 修改配置文件"></a>5.2、 修改配置文件</h3><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 拷贝配置文件</span><br><span class="line"><span class="keyword">cd</span> /<span class="keyword">opt</span>/spark</span><br><span class="line"><span class="keyword">cp</span> ./<span class="keyword">conf</span>/spark-env.<span class="keyword">sh</span>.template ./<span class="keyword">conf</span>/spark-env.<span class="keyword">sh</span></span><br><span class="line"></span><br><span class="line"># 修改配置文件</span><br><span class="line"><span class="keyword">vim</span> ./<span class="keyword">conf</span>/spark-env.<span class="keyword">sh</span></span><br><span class="line"># 在最后添加下面的代码</span><br><span class="line">export SPARK_DIST_CLASSPATH=$(/<span class="keyword">opt</span>/hadoop/bin/hadoop classpath)</span><br><span class="line">export JAVA_HOME=/<span class="keyword">opt</span>/jdk</span><br></pre></td></tr></table></figure>
<h3 id="5-3、运行examples验证安装"><a href="#5-3、运行examples验证安装" class="headerlink" title="5.3、运行examples验证安装"></a>5.3、运行examples验证安装</h3><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta-keyword">/opt/</span>spark<span class="meta-keyword">/bin/</span>run-example SparkPi <span class="number">2</span>&gt;<span class="variable">&amp;1</span> | grep <span class="string">"Pi is roughly"</span></span><br><span class="line"><span class="meta"># output</span></span><br><span class="line"><span class="meta"># Pi is roughly 3.143635718178591</span></span><br></pre></td></tr></table></figure>
<h3 id="5-4、-脚本启动Hadoop和Spark"><a href="#5-4、-脚本启动Hadoop和Spark" class="headerlink" title="5.4、 脚本启动Hadoop和Spark"></a>5.4、 脚本启动Hadoop和Spark</h3><ul>
<li><p>启动spark</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/<span class="keyword">opt</span>/spark/sbin/start-<span class="keyword">all</span>.<span class="keyword">sh</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>通过WEB页面查看</p>
<blockquote>
<p> 浏览器输入地址：<a href="http://localhost:8080" target="_blank" rel="noopener">http://localhost:8080</a></p>
</blockquote>
</li>
<li><p>编写自动化脚本</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动Hadoop以及Spark脚本</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># 启动Hadoop以及yarn</span></span><br><span class="line">start-dfs.sh</span><br><span class="line">start-yarn.sh</span><br><span class="line"><span class="comment"># 启动历史服务器</span></span><br><span class="line"><span class="comment">#mr-jobhistory-daemon.sh start historyserver</span></span><br><span class="line">mapred --daemon start historyserver</span><br><span class="line"><span class="comment"># 启动Spark</span></span><br><span class="line">/opt/spark/sbin/start-all.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止Hadoop以及Spark脚本</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># 停止Hadoop以及yarn</span></span><br><span class="line">stop-dfs.sh</span><br><span class="line">stop-yarn.sh</span><br><span class="line"><span class="comment"># 停止历史服务器</span></span><br><span class="line"><span class="comment">#mr-jobhistory-daemon.sh stop historyserver</span></span><br><span class="line">mapred --daemon stop historyserver</span><br><span class="line"><span class="comment"># 停止Spark</span></span><br><span class="line">/opt/spark/sbin/stop-all.sh</span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://heany.github.io/2018/04/08/Ubuntu-17-10配置Hadoop-Spark环境/" data-id="cjrdmm6pf001y313hba2k1ksd" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Ubuntu-17-10-hadoop-Spark/">Ubuntu 17.10 hadoop Spark</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/04/09/sublime-text-3-最新的注册码/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          sublime text 3 最新的注册码
        
      </div>
    </a>
  
  
    <a href="/2018/03/31/Shell-Script学习笔记/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Shell Script学习笔记</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Github/">Github</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MySQL/">MySQL</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Script/">Script</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Website/">Website</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/其他/">其他</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/分布式与大数据/">分布式与大数据</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/常用工具/">常用工具</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/">技术</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Docker/">Docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Markdown/">Markdown</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nginx-php-MySQL/">Nginx-php-MySQL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Numpy-Random/">Numpy Random</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Shell-linux/">Shell linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TF-IDF-Algorithm/">TF-IDF-Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ubuntu-17-10-hadoop-Spark/">Ubuntu 17.10 hadoop Spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/">git</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo-Blog/">hexo Blog</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo-Github-Pages-Blog/">hexo Github-Pages Blog</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo常用命令/">hexo常用命令</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python3/">python3</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python学习笔记/">python学习笔记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sublime-插件/">sublime 插件</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sublime-text-3-注册码/">sublime-text-3 注册码</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sublime插件/">sublime插件</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据挖掘/">数据挖掘</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/贝叶斯分类器/">贝叶斯分类器</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/Docker/" style="font-size: 10px;">Docker</a> <a href="/tags/Markdown/" style="font-size: 10px;">Markdown</a> <a href="/tags/Nginx-php-MySQL/" style="font-size: 10px;">Nginx-php-MySQL</a> <a href="/tags/Numpy-Random/" style="font-size: 10px;">Numpy Random</a> <a href="/tags/Shell-linux/" style="font-size: 10px;">Shell linux</a> <a href="/tags/TF-IDF-Algorithm/" style="font-size: 10px;">TF-IDF-Algorithm</a> <a href="/tags/Ubuntu-17-10-hadoop-Spark/" style="font-size: 10px;">Ubuntu 17.10 hadoop Spark</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/hexo-Blog/" style="font-size: 10px;">hexo Blog</a> <a href="/tags/hexo-Github-Pages-Blog/" style="font-size: 10px;">hexo Github-Pages Blog</a> <a href="/tags/hexo常用命令/" style="font-size: 10px;">hexo常用命令</a> <a href="/tags/python3/" style="font-size: 10px;">python3</a> <a href="/tags/python学习笔记/" style="font-size: 20px;">python学习笔记</a> <a href="/tags/sublime-插件/" style="font-size: 10px;">sublime 插件</a> <a href="/tags/sublime-text-3-注册码/" style="font-size: 10px;">sublime-text-3 注册码</a> <a href="/tags/sublime插件/" style="font-size: 10px;">sublime插件</a> <a href="/tags/数据挖掘/" style="font-size: 10px;">数据挖掘</a> <a href="/tags/贝叶斯分类器/" style="font-size: 10px;">贝叶斯分类器</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/06/08/mysql操作使用变量作为表名/">mysql操作使用变量作为表名</a>
          </li>
        
          <li>
            <a href="/2018/06/06/Numpy的random函数汇总/">Numpy的random函数汇总</a>
          </li>
        
          <li>
            <a href="/2018/05/15/Nginx-PHP-MySQL搭建过程/">Nginx+PHP+MySQL搭建过程</a>
          </li>
        
          <li>
            <a href="/2018/05/14/TF-IDF理解/">TF-IDF理解</a>
          </li>
        
          <li>
            <a href="/2018/04/18/删除Github-com上repository中的某个文件夹/">删除Github.com上repository中的某个文件夹</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Heany<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>